{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "第4章_章末演習問題.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WehYXzWpwhi1"
      },
      "source": [
        "第4章の章末演習問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRoPRKcMwlbZ"
      },
      "source": [
        "### [1] 携帯電話やデジタルカメラで、赤、青、緑の物体の写真を何枚か撮りましょう（カメラがない場合は、インターネットからダウンロードすることもできます）。\n",
        "※ ここではGoogle Colaraboratoryでの実行を想定しています。\n"
      ]
    },
    {
      "source": [
        "※本フォルダに、無料写真素材　写真AC（商用利用可）のデータを配置しています。\n",
        "\n",
        "apple.jpg、sky.jpg、forest.jpg\n",
        "\n",
        "\n",
        "https://www.photo-ac.com/main/detail/345453?title=%E3%83%AA%E3%83%B3%E3%82%B4&searchId=68658080\n",
        "\n",
        "https://www.photo-ac.com/main/detail/3343123?title=%E3%81%99%E3%81%A3%E3%81%8D%E3%82%8A%E6%99%B4%E3%82%8C%E3%82%84%E3%81%8B%E3%81%AA%E5%A4%8F%E3%81%AE%E7%A9%BA&searchId=68660407\n",
        "\n",
        "https://www.photo-ac.com/main/detail/3518379?title=%E6%A8%B9%E6%9C%A8_%E6%A3%AE%E6%9E%97_3&searchId=68662146\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YnFAcuysEQDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#### （a）各画像を読み込み、テンソルに変換してください。"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FSZC8BAJw9A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kduB0LXvxL0b"
      },
      "source": [
        "# 回答\n",
        "import numpy as np\n",
        "import torch\n",
        "torch.set_printoptions(edgeitems=2, threshold=50)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2336, 4160, 3), (4160, 2336, 3), (3120, 4160, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "img_arr_r = imageio.imread('../data/p1ch4/red.jpg')\n",
        "img_arr_g = imageio.imread('../data/p1ch4/green.jpg')\n",
        "img_arr_b = imageio.imread('../data/p1ch4/blue.jpg')\n",
        "img_arr_r.shape, img_arr_g.shape, img_arr_b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "from_numpy() takes no keyword arguments",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-7a1a525f72d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mout_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mout_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: from_numpy() takes no keyword arguments"
          ]
        }
      ],
      "source": [
        "img_r = torch.from_numpy(img_arr_r)\n",
        "img_g = torch.from_numpy(img_arr_g)\n",
        "img_b = torch.from_numpy(img_arr_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_r_f = img_r.to(dtype=torch.float)\n",
        "img_g_f = img_g.to(dtype=torch.float)\n",
        "img_b_f = img_b.to(dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2336, 4160]),\n",
              " torch.Size([3, 4160, 2336]),\n",
              " torch.Size([3, 3120, 4160]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "out_r = img_r_f.permute(2, 0, 1)\n",
        "out_g = img_g_f.permute(2, 0, 1)\n",
        "out_b = img_b_f.permute(2, 0, 1)\n",
        "out_r.shape, out_g.shape, out_b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "out_r.dtype"
      ]
    },
    {
      "source": [
        "#### (b）各画像テンソルについて、.mean()メソッドを使用して、画像の明るさを求めてください。"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YO24ioODyKtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_7dlCScyWYr"
      },
      "source": [
        "# 回答 dim=1で次元1で平均する\n",
        "torch.mean(out_r, dim=1), torch.mean(out_g, dim=1), torch.mean(out_b, dim=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 79.6667,  78.6667,  ...,  76.0000,  76.0000],\n",
              "         [ 76.6667,  75.6667,  ...,  74.0000,  76.0000],\n",
              "         ...,\n",
              "         [186.0000, 185.0000,  ...,  42.0000,  41.0000],\n",
              "         [184.0000, 184.0000,  ...,  44.0000,  43.0000]]),\n",
              " tensor([[124.0000, 125.0000,  ..., 137.3333, 133.3333],\n",
              "         [127.0000, 126.0000,  ..., 131.3333, 140.3333],\n",
              "         ...,\n",
              "         [ 92.0000,  93.0000,  ..., 150.0000, 155.0000],\n",
              "         [ 94.0000,  88.0000,  ..., 147.0000, 149.3333]]),\n",
              " tensor([[145.3333, 145.3333,  ..., 113.0000, 113.0000],\n",
              "         [141.3333, 143.3333,  ..., 112.0000, 113.0000],\n",
              "         ...,\n",
              "         [173.6667, 169.6667,  ..., 210.6667, 211.6667],\n",
              "         [170.6667, 167.6667,  ..., 211.6667, 212.6667]]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2336, 4160]), torch.Size([3, 4160]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 次元1が平均されたことで次元が減ったことの確認\n",
        "out_r.shape, torch.mean(out_r, dim=1).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6rfvnbqJloe"
      },
      "source": [
        "#### （c）各画像の各チャンネルの平均を取ってください。求めたチャンネルの平均値だけから、赤、緑、青の物体を識別できるか確認してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41982_5lCCUL"
      },
      "source": [
        "# さらに、次元1，2で平均する　平均対象の次元を逐次的に指定する\n",
        "# 回答 赤\n",
        "torch.mean(out_r, dim=1).mean(dim=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([132.3350, 109.1540, 109.0145]),)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([143.6180, 157.2123, 145.9531])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# 回答 緑\n",
        "torch.mean(out_g, dim=1).mean(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([125.8333, 124.3068, 106.6931])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# 回答 青\n",
        "torch.mean(out_b, dim=1).mean(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdWttSfHzGKz"
      },
      "source": [
        "### [2] Pythonのソースコードを含む比較的大きなファイルを用意してください。\n",
        "\n",
        "※https://github.com/YutaroOgawa/pytorch_advanced/blob/master/1_image_classification/utils/dataloader_image_classification.py\n",
        "\n",
        "をフォルダ内に用意しています。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yzctZuLzODR"
      },
      "source": [
        "#### （a）ソースファイル内のすべての単語のインデックスを作成してください (トークン化はシンプルにしても複雑にしても構いません。 最初は正規表現r\"[^a-zA-Z0-9_]+\"とスペースで、単語を一度置き換えることをおすすめします)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFq3TaQBy-ZE"
      },
      "source": [
        "# 回答\n",
        "with open('./data_loader.py', encoding='utf8') as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['import', 'glob', 'import', 'os', 'path', 'as', 'osp', 'import', 'torch', 'utils', 'data', 'as', 'data', 'from', 'torchvision', 'import', 'models', 'transforms', 'from', 'PIL', 'import', 'Image', 'class', 'ImageTransform', 'RandomResizedCrop', 'RandomHorizontalFlip', 'Attributes', 'resize', 'int', 'mean', 'R', 'G', 'B', 'std', 'R', 'G', 'B', 'def', '__init__', 'self', 'resize', 'mean', 'std', 'self', 'data_transform', 'train', 'transforms', 'Compose', 'transforms', 'RandomResizedCrop', 'resize', 'scale', '0', '5', '1', '0', 'transforms', 'RandomHorizontalFlip', 'transforms', 'ToTensor', 'transforms', 'Normalize', 'mean', 'std', 'val', 'transforms', 'Compose', 'transforms', 'Resize', 'resize', 'transforms', 'CenterCrop', 'resize', 'resize', 'resize', 'transforms', 'ToTensor', 'transforms', 'Normalize', 'mean', 'std', 'def', '__call__', 'self', 'img', 'phase', 'train', 'Parameters', 'phase', 'train', 'or', 'val', 'return', 'self', 'data_transform', 'phase', 'img', 'def', 'make_datapath_list', 'phase', 'train', 'Parameters', 'phase', 'train', 'or', 'val', 'Returns', 'path_list', 'list', 'rootpath', 'data', 'hymenoptera_data', 'target_path', 'osp', 'join', 'rootpath', 'phase', 'jpg', 'print', 'target_path', 'path_list', 'glob', 'for', 'path', 'in', 'glob', 'glob', 'target_path', 'path_list', 'append', 'path', 'return', 'path_list', 'class', 'HymenopteraDataset', 'data', 'Dataset', 'Dataset', 'PyTorch', 'Dataset', 'Attributes', 'file_list', 'transform', 'object', 'phase', 'train', 'or', 'test', 'def', '__init__', 'self', 'file_list', 'transform', 'None', 'phase', 'train', 'self', 'file_list', 'file_list', 'self', 'transform', 'transform', 'self', 'phase', 'phase', 'train', 'or', 'val', 'def', '__len__', 'self', 'return', 'len', 'self', 'file_list', 'def', '__getitem__', 'self', 'index', 'Tensor', 'index', 'img_path', 'self', 'file_list', 'index', 'img', 'Image', 'open', 'img_path', 'RGB', 'img_transformed', 'self', 'transform', 'img', 'self', 'phase', 'torch', 'Size', '3', '224', '224', 'if', 'self', 'phase', 'train', 'label', 'img_path', '30', '34', 'elif', 'self', 'phase', 'val', 'label', 'img_path', '28', '32', 'if', 'label', 'ants', 'label', '0', 'elif', 'label', 'bees', 'label', '1', 'return', 'img_transformed', 'label']\n"
          ]
        }
      ],
      "source": [
        "# 正規表現で抽出 以下のURLを参考\n",
        "# https://techacademy.jp/magazine/19307\n",
        "import re\n",
        "words_in_file = re.findall(r\"[a-zA-Z0-9_]+\", text) # 文字と数字\n",
        "\n",
        "print(words_in_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBEZN-2gzy-P"
      },
      "source": [
        "#### （b）本章の「高慢と偏見」で作ったインデックスと比較してみてください。どちらの方がサイズは大きいですか？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e-l9C2S5Ihj"
      },
      "source": [
        "# 回答\n",
        "len(words_in_file)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# 重複を消し、並び替える\n",
        "word_list = list(set(words_in_file)) # setで同一語を1つにする= 重複排除\n",
        "word_list = sorted(word_list)\n",
        "len(word_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 86)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "word2index_dict = {word: i for (i, word) in enumerate(word_list)}\n",
        "\n",
        "len(word2index_dict), word2index_dict['transform']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei2PjV2b1pVy"
      },
      "source": [
        "#### （c）ソースコードファイルのワンホットエンコーディングを作成してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ij9x9461uDC"
      },
      "source": [
        "# 回答"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT84rW88KnwC"
      },
      "source": [
        "#### （d）今回のエンコーディングで失われる情報は何でしょうか？本章での「高慢と偏見」のエンコーディングで失われた情報と比較してみてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgJ_bDJzKrcA"
      },
      "source": [
        "# 回答\n",
        "# 単語の並び、単語間の関係、回数など"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqu60yKps9Rh"
      },
      "source": [
        "#　省略"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RKZsWxPz6kz"
      },
      "source": [
        "以上。\n"
      ]
    }
  ]
}